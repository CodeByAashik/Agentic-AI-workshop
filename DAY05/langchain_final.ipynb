{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e722eb8b",
   "metadata": {},
   "source": [
    "\n",
    "## A Practical Guide to Building LLM Applications\n",
    "\n",
    "This notebook provides a hands-on introduction to LangChain, covering essential concepts and practical implementations for working with large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e0606",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment Setup & Configuration\n",
    "\n",
    "First, let's load environment variables and set up our workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04092f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Loads API keys from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c933e",
   "metadata": {},
   "source": [
    "**Key Concepts:**\n",
    "- `load_dotenv()` reads environment variables from a `.env` file\n",
    "- This keeps API keys secure and out of your code\n",
    "- Required for authentication with LLM providers (OpenAI, Google, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e7183",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Understanding LLMs and Chat Models\n",
    "\n",
    "### What are Large Language Models (LLMs)?\n",
    "LLMs are advanced neural networks trained on massive text datasets using transformer architecture. They predict the next token based on context, enabling human-like text generation.\n",
    "\n",
    "### LangChain's Abstraction Layer\n",
    "LangChain provides a unified interface for different LLM providers because:\n",
    "- Different APIs have different authentication methods and parameters\n",
    "- Unified interface allows switching models with minimal code changes\n",
    "- Enables building complex chains that work across providers\n",
    "\n",
    "###  Chat Models vs Raw LLMs\n",
    "| Feature | Chat Models | Raw LLMs |\n",
    "|---------|-------------|----------|\n",
    "| **Optimization** | Multi-turn conversations | Text completion |\n",
    "| **Message Structure** | System/User/Assistant roles | Plain text |\n",
    "| **Context** | Maintains conversation history | Stateless |\n",
    "| **Best for** | Dialogues, assistants | Text generation, summarization |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3842329",
   "metadata": {},
   "source": [
    "## 3. Integrating Different LLM Providers\n",
    "\n",
    "### 3.1 OpenAI Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f609fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",   # Model version\n",
    "    temperature=0,         # Controls randomness (0-2)\n",
    "    # max_tokens=100,      # Optional: limit response length\n",
    "    # timeout=30,          # Optional: request timeout\n",
    ")\n",
    "\n",
    "response = openai_llm.invoke(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ca4a0",
   "metadata": {},
   "source": [
    "**Temperature Parameter Explained:**\n",
    "- **0.0-0.3**: Deterministic, consistent responses\n",
    "- **0.4-0.7**: Balanced creativity and consistency\n",
    "- **0.8-1.2**: Creative, varied responses\n",
    "- **1.3-2.0**: Highly creative, less predictable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb11359",
   "metadata": {},
   "source": [
    "### 3.2 Google Gemini Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2618dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=1.0,      # More creative responses\n",
    "    max_tokens=None,      # No token limit\n",
    "    timeout=None,         # No timeout\n",
    "    max_retries=2,        # Automatic retry on failure\n",
    ")\n",
    "\n",
    "response = google_llm.invoke(\"what is ai?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417ba03",
   "metadata": {},
   "source": [
    "### 3.3 HuggingFace Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "# Using HuggingFace's hosted inference API\n",
    "hf_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"deepseek-ai/DeepSeek-V3.2\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512, \n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=hf_llm)\n",
    "response = chat_model.invoke(\"What is the capital of Italy?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b078d82",
   "metadata": {},
   "source": [
    "**Benefits of Open-Source Models:**\n",
    "- **No API Costs**: Run locally or on your infrastructure\n",
    "- **Data Privacy**: No external API calls for sensitive data\n",
    "- **Customization**: Fine-tune for specific domains\n",
    "- **Transparency**: Full control over model behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1dd23",
   "metadata": {},
   "source": [
    "## 4. Working with Embeddings\n",
    "\n",
    "### What are Embeddings?\n",
    "Embeddings convert text into numerical vectors that capture semantic meaning. Similar concepts have similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize embeddings model\n",
    "openai_embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Convert text to vector\n",
    "vector = openai_embedding.embed_query(\"Hello world\")\n",
    "print(f\"Vector dimension: {len(vector)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04070965",
   "metadata": {},
   "source": [
    "\n",
    "**Understanding Embeddings:**\n",
    "- Each word/sentence becomes a point in high-dimensional space\n",
    "- Similar meanings = Closer points in vector space\n",
    "- Enables mathematical operations on text (similarity, clustering, etc.)\n",
    "\n",
    "**Practical Applications:**\n",
    "1. **Semantic Search**: Find documents by meaning, not keywords\n",
    "2. **RAG Systems**: Retrieve relevant context for LLM queries\n",
    "3. **Clustering**: Group similar documents automatically\n",
    "4. **Recommendations**: Suggest similar items based on content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505591f",
   "metadata": {},
   "source": [
    "## 5. Crafting Effective Prompts\n",
    "\n",
    "### 5.1 Basic Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=1.0,      # More creative responses\n",
    "    max_tokens=None,      # No token limit\n",
    "    timeout=None,         # No timeout\n",
    "    max_retries=2,        # Automatic retry on failure\n",
    ")\n",
    "\n",
    "# Create reusable template\n",
    "TEMPLATE = \"\"\" \n",
    "What is the capital of {country}?\n",
    "Also provide some {additional_info}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=TEMPLATE,\n",
    "    input_variables=[\"country\", \"additional_info\"]\n",
    ")\n",
    "\n",
    "# Format the template\n",
    "formatted_prompt = prompt_template.format(\n",
    "    country=\"Italy\",\n",
    "    additional_info=\"tourist attractions\"\n",
    ")\n",
    "print(formatted_prompt)\n",
    "response = google_llm.invoke(formatted_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af531726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d557345",
   "metadata": {},
   "source": [
    "**Why Use Templates?**\n",
    "- **Consistency**: Standardized prompt structure\n",
    "- **Reusability**: Use same template across different inputs\n",
    "- **Maintainability**: Update prompts in one place\n",
    "- **Testing**: Easy to test different prompt variations\n",
    "- **Validation**: Provides built in validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba277fb",
   "metadata": {},
   "source": [
    "### 5.2 The Stateless Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = google_llm.invoke(\"Hello! I am Sandesh Dhital\")\n",
    "print(response1.content)\n",
    "\n",
    "response2 = google_llm.invoke(\"Can you tell my name?\")\n",
    "print(response2.content)  # LLM doesn't remember!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b67fca",
   "metadata": {},
   "source": [
    "**The Challenge:**\n",
    "- Each API call is independent\n",
    "- No memory between requests\n",
    "- Real conversations need context\n",
    "\n",
    "**The Solution:**\n",
    "- Maintain message history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49069aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# Initialize conversation\n",
    "message_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "]\n",
    "\n",
    "# Simulate conversation\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hi, I'm Aashik\"),\n",
    "    AIMessage(content=\"Hello Aashik! How can I help?\"),\n",
    "    HumanMessage(content=\"Why is python considered beginner friendly?\"),\n",
    "]\n",
    "\n",
    "# Send entire history\n",
    "response = google_llm.invoke(message_history + messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8051c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb948537",
   "metadata": {},
   "source": [
    "### 5.3 Multi-Turn Conversations\n",
    "\n",
    "\n",
    "\n",
    "**Message Types:**\n",
    "- **SystemMessage**: Sets behavior/role (invisible to user)\n",
    "- **HumanMessage**: User inputs/questions\n",
    "- **AIMessage**: Model responses (for context)\n",
    "\n",
    "**Best Practices:**\n",
    "1. Start with a clear SystemMessage\n",
    "2. Append all messages to history\n",
    "3. Consider token limits (long histories = more tokens)\n",
    "4. Use summarization for very long conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc208e00",
   "metadata": {},
   "source": [
    "### 5.4 Advanced Chat Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad822a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Structured chat template with roles\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful {domain} expert'),\n",
    "    ('human', 'Explain in simple terms, what is {topic}')\n",
    "])\n",
    "\n",
    "# Format with variables\n",
    "prompt = chat_template.invoke({\n",
    "    'domain': 'cricket',\n",
    "    'topic': 'NPL'\n",
    "})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e7b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7a79900",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Structured Output Generation\n",
    "\n",
    "### 6.1 Using TypedDict for Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419cfb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key_themes': ['processor performance', 'camera quality', 'battery life', 'S-Pen', 'design and ergonomics', 'software bloatware', 'price'], 'summary': 'The Samsung Galaxy S24 Ultra offers exceptional performance with its Snapdragon 8 Gen 3 processor, a stunning 200MP camera with great night mode and zoom capabilities, and a long-lasting battery with fast charging. The S-Pen is a useful addition. However, its size and weight can be a drawback for one-handed use, One UI has bloatware, and the price is high.', 'sentiment': 'pos', 'pros': ['Insanely powerful Snapdragon 8 Gen 3 processor, great for gaming and productivity', 'Stunning 200MP camera with incredible night mode and good zoom capabilities up to 30x', 'Long-lasting 5000mAh battery with 45W fast charging', 'S-Pen support is unique and useful for note-taking and sketches'], 'cons': ['Weight and size make it uncomfortable for one-handed use', \"Samsung's One UI still comes with bloatware\", 'High price tag of $1,300', 'Zoom beyond 30x loses quality'], 'name': 'Samsung Galaxy S24 Ultra'}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Optional, Literal\n",
    "\n",
    "# Define expected output structure\n",
    "class Review(TypedDict):\n",
    "    key_themes: Annotated[list[str], \"Key themes in the review\"]\n",
    "    summary: Annotated[str, \"Brief summary\"]\n",
    "    sentiment: Annotated[Literal[\"pos\", \"neg\"], \"Sentiment\"]\n",
    "    pros: Annotated[Optional[list[str]], \"List of pros\"]\n",
    "    cons: Annotated[Optional[list[str]], \"List of cons\"]\n",
    "    name: Annotated[Optional[str], \"Name of the person who had reviewed\"]\n",
    "\n",
    "# Configure LLM for structured output\n",
    "structured_llm = google_llm.with_structured_output(Review)\n",
    "\n",
    "review=\"\"\"\n",
    "I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, itâ€™s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fastâ€”whether Iâ€™m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n",
    "\n",
    "The S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP cameraâ€”the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n",
    "\n",
    "However, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsungâ€™s One UI still comes with bloatwareâ€”why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n",
    "\n",
    "Pros:\n",
    "Insanely powerful processor (great for gaming and productivity)\n",
    "Stunning 200MP camera with incredible zoom capabilities\n",
    "Long battery life with fast charging\n",
    "S-Pen support is unique and useful\n",
    "                                 \n",
    "Review by Sandesh Dhital\"\"\"\n",
    "\n",
    "# Get structured response\n",
    "result = structured_llm.invoke(review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d81e1",
   "metadata": {},
   "source": [
    "**Why Structured Output?**\n",
    "- **Reliable Parsing**: No regex or manual parsing\n",
    "- **Type Safety**: Guaranteed data types\n",
    "- **Validation**: Built-in schema validation\n",
    "- **Integration**: Easy to use with databases/APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define schema with validation\n",
    "class Review(BaseModel):\n",
    "    key_themes: list[str] = Field(description=\"Key themes in list\")\n",
    "    summary: str = Field(description=\"Brief summary\")\n",
    "    sentiment: Literal[\"pos\", \"neg\"] = Field(description=\"Sentiment\")\n",
    "    pros: Optional[list[str]] = Field(default=None, description=\"Pros list\")\n",
    "    cons: Optional[list[str]] = Field(default=None, description=\"Cons list\")\n",
    "    name: Optional[str] = Field(default=None, description=\"Reviewer name\")\n",
    "\n",
    "# Use with LLM\n",
    "structured_llm = openai_llm.with_structured_output(Review)\n",
    "\n",
    "review=\"\"\"\n",
    "I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, itâ€™s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fastâ€”whether Iâ€™m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n",
    "\n",
    "The S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP cameraâ€”the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n",
    "\n",
    "However, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsungâ€™s One UI still comes with bloatwareâ€”why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n",
    "\n",
    "Pros:\n",
    "Insanely powerful processor (great for gaming and productivity)\n",
    "Stunning 200MP camera with incredible zoom capabilities\n",
    "Long battery life with fast charging\n",
    "S-Pen support is unique and useful\n",
    "                                 \n",
    "Review by Sandesh Dhital\"\"\"\n",
    "\n",
    "# Get structured response\n",
    "result = structured_llm.invoke(review)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a15e08",
   "metadata": {},
   "source": [
    "\n",
    "**Pydantic Advantages:**\n",
    "- **Runtime Validation**: Catches invalid data\n",
    "- **Rich Features**: Default values, validators, serialization\n",
    "- **Better Integration**: Works with FastAPI, databases\n",
    "- **Documentation**: Auto-generated API docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa9a66",
   "metadata": {},
   "source": [
    "### 6.3 Using JSON Schema (Maximum Flexibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d4ab24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai_llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 45\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# schema\u001b[39;00m\n\u001b[0;32m      2\u001b[0m json_schema \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_themes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     42\u001b[0m }\n\u001b[1;32m---> 45\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m openai_llm\u001b[38;5;241m.\u001b[39mwith_structured_output(json_schema)\n\u001b[0;32m     47\u001b[0m review\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124mI recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, itâ€™s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fastâ€”whether Iâ€™m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\u001b[39m\n\u001b[0;32m     49\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124m                                 \u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124mReview by Sandesh Dhital\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Get structured response\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'openai_llm' is not defined"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "json_schema = {\n",
    "  \"title\": \"Review\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"key_themes\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the key themes discussed in the review in a list\"\n",
    "    },\n",
    "    \"summary\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A brief summary of the review\"\n",
    "    },\n",
    "    \"sentiment\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"pos\", \"neg\"],\n",
    "      \"description\": \"Return sentiment of the review either negative, positive or neutral\"\n",
    "    },\n",
    "    \"pros\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the pros inside a list\"\n",
    "    },\n",
    "    \"cons\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the cons inside a list\"\n",
    "    },\n",
    "    \"name\": {\n",
    "      \"type\": [\"string\", \"null\"],\n",
    "      \"description\": \"Write the name of the reviewer\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"key_themes\", \"summary\", \"sentiment\"]\n",
    "}\n",
    "\n",
    "\n",
    "structured_llm = openai_llm.with_structured_output(json_schema)\n",
    "\n",
    "review=\"\"\"\n",
    "I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, itâ€™s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fastâ€”whether Iâ€™m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n",
    "\n",
    "The S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP cameraâ€”the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n",
    "\n",
    "However, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsungâ€™s One UI still comes with bloatwareâ€”why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n",
    "\n",
    "Pros:\n",
    "Insanely powerful processor (great for gaming and productivity)\n",
    "Stunning 200MP camera with incredible zoom capabilities\n",
    "Long battery life with fast charging\n",
    "S-Pen support is unique and useful\n",
    "                                 \n",
    "Review by Sandesh Dhital\"\"\"\n",
    "\n",
    "# Get structured response\n",
    "result = structured_llm.invoke(review)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31835438",
   "metadata": {},
   "source": [
    "**JSON Schema Benefits:**\n",
    "- **Language Agnostic**: Works across programming languages\n",
    "- **Standard Format**: Widely supported in APIs\n",
    "- **Complex Constraints**: Advanced validation rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5ed32",
   "metadata": {},
   "source": [
    "# 7.LangChain Output Parsers \n",
    "\n",
    "\n",
    "This section provides an in-depth guide to LangChain's output parsers, covering `StrOutputParser`, `JsonOutputParser`, `StructuredOutputParser`, and `PydanticOutputParser` with practical examples.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214858e1",
   "metadata": {},
   "source": [
    "## 7.1 Introduction to Output Parsers\n",
    "\n",
    "### Why Output Parsers Matter\n",
    "LLMs generate unstructured text, but real applications need structured data. Output parsers solve this by:\n",
    "- **Extracting structured data** from text responses\n",
    "- **Validating** outputs against schemas\n",
    "- **Normalizing** inconsistent formats\n",
    "- **Enabling** reliable downstream processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77482c86",
   "metadata": {},
   "source": [
    "## 7.2 StrOutputParser - Simple Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize components\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Create simple chain\n",
    "prompt = PromptTemplate.from_template(\"Summarize this text: {text}\")\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# Execute\n",
    "text = \"Large Language Models (LLMs) are AI systems trained on vast amounts of text data...\"\n",
    "result = chain.invoke({\"text\": text})\n",
    "\n",
    "print(\"StrOutputParser Result:\")\n",
    "print(f\"Content: {result}\")\n",
    "print(f\"Type: {type(result)}\")  # <class 'str'>\n",
    "print(f\"Length: {len(result)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe8588",
   "metadata": {},
   "source": [
    "\n",
    "**Key Points:**\n",
    "- Returns raw string output\n",
    "- No validation or structure\n",
    "- Fastest and simplest parser\n",
    "- Good for text-only responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f72273",
   "metadata": {},
   "source": [
    "## 7.3 JsonOutputParser - Structured JSON Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf682de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      9\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mExtract the following information as JSON:\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     }\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Create chain\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m parser\n\u001b[0;32m     23\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124mCustomer: John Smith\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124mEmail: john@example.com\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124mItems: Laptop, Mouse, Keyboard\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     33\u001b[0m result \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Initialize JSON parser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Create prompt with format instructions\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Extract the following information as JSON:\n",
    "    {text}\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "text = \"\"\"\n",
    "Customer: John Smith\n",
    "Email: john@example.com\n",
    "Order: #12345\n",
    "Total: $199.99\n",
    "Status: Delivered\n",
    "Date: 2024-03-15\n",
    "Items: Laptop, Mouse, Keyboard\n",
    "\"\"\"\n",
    "\n",
    "result = chain.invoke({\"text\": text})\n",
    "\n",
    "print(\"JsonOutputParser Result:\")\n",
    "print(f\"Parsed: {result}\")\n",
    "print(f\"Type: {type(result)}\")  # <class 'dict'>\n",
    "print(f\"Keys: {list(result.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4ba0e",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- Extracts JSON from LLM responses\n",
    "- Can validate JSON syntax\n",
    "- Good for structured data exchange\n",
    "- Works with any JSON-compliant output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71790d7",
   "metadata": {},
   "source": [
    "## 7.4 StructuredOutputParser - Custom Format Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define output schema\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"summary\", description=\"Brief summary\"),\n",
    "    ResponseSchema(name=\"sentiment\", description=\"Positive/Neutral/Negative\"),\n",
    "    ResponseSchema(name=\"keywords\", description=\"List of keywords\"),\n",
    "    ResponseSchema(name=\"confidence\", description=\"Confidence score 0-1\", type=\"float\")\n",
    "]\n",
    "\n",
    "# Create parser\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"Format Instructions:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# Create prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Analyze this text:\n",
    "    {text}\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# Execute\n",
    "text = \"The new smartphone features an amazing camera, fast processor, but battery life could be better.\"\n",
    "result = chain.invoke({\"text\": text})\n",
    "\n",
    "print(\"\\nStructuredOutputParser Result:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value} (type: {type(value).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedccf64",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- Highly flexible structure definition\n",
    "- Custom delimiters and patterns\n",
    "- Supports nested schemas\n",
    "- Good for complex extraction tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47f47e",
   "metadata": {},
   "source": [
    "## 7.5 PydanticOutputParser - Type-Safe Excellence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49538054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define the model\n",
    "llm=ChatOpenAI()\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "\n",
    "    name: str = Field(description='Name of the person')\n",
    "    age: int = Field(gt=18, description='Age of the person')\n",
    "    city: str = Field(description='Name of the city the person belongs to')\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Generate the name, age and city of a fictional {place} person \\n {format_instruction}',\n",
    "    input_variables=['place'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | llm | parser\n",
    "\n",
    "final_result = chain.invoke({'place':'sri lankan'})\n",
    "\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db3b5b",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- Full type safety with runtime validation\n",
    "- Complex validation rules and computed properties\n",
    "- Best for production systems requiring reliability\n",
    "- Excellent integration with Python ecosystem\n",
    "- Can be combined with other parsers for fallback strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e097f6",
   "metadata": {},
   "source": [
    "\n",
    "###  Useful Resources\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [OpenAI API Docs](https://platform.openai.com/docs/)\n",
    "- [HuggingFace Models](https://huggingface.co/models)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
    "\n",
    "\n",
    "\n",
    "**ðŸ’¡ Remember**: Start simple, test often, and iterate based on results. LLM applications are experimental - expect to adjust prompts and parameters based on your specific use case!\n",
    "\n",
    "Happy building! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
