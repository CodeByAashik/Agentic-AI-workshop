{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "il-H3FWHfCV1",
        "outputId": "88383cbb-e9cc-46dd-9ee0-e0e571ac3e83"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core langchain-community pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3Baoz4rfSAx"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ8xxQMsfao6",
        "outputId": "a38130ec-8a65-4adc-e8b4-8a6dc33faa2e"
      },
      "outputs": [],
      "source": [
        "doc=Document(\n",
        "    page_content=\"Hello world\",\n",
        "    metadata={\n",
        "        \"source\":\"example.txt\",\n",
        "        \"pages\":1,\n",
        "        \"author\":\"Aashik Thakur\",\n",
        "        \"date_created\":\"2025-12-17\"\n",
        "    }\n",
        ")\n",
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOhW-Ma5g3o6",
        "outputId": "50f10beb-f327-43f7-f6b1-625e1926af12"
      },
      "outputs": [],
      "source": [
        "### TextLoader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "loader=TextLoader(\"text-files/ai.txt\",encoding=\"utf-8\")\n",
        "document=loader.load()\n",
        "print(document)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cwpu_Mth7ID",
        "outputId": "f9e2e2ef-9976-4ea4-f2bd-d66b0b0bb4f1"
      },
      "outputs": [],
      "source": [
        "### directory loader\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "## load all the files from a directory\n",
        "dir_loader=DirectoryLoader(\n",
        "    \"text-files\",\n",
        "    glob=\"**/*.txt\", ##pattern to match files\n",
        "    loader_cls=TextLoader, ## loader class to use\n",
        "    loader_kwargs={\"encoding\":\"utf-8\"}\n",
        ")\n",
        "documents=dir_loader.load()\n",
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d6hIzhdTlS4K",
        "outputId": "86dea06e-55c5-444b-dfb3-f758317a8c21"
      },
      "outputs": [],
      "source": [
        "### load a pdf file\n",
        "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
        "\n",
        "dir_loader=DirectoryLoader(\n",
        "    \"pdf-files\",\n",
        "    glob=\"**/*.pdf\", ##pattern to match files\n",
        "    loader_cls=PyMuPDFLoader ## loader class to use\n",
        ")\n",
        "\n",
        "pdf_documents = dir_loader.load()\n",
        "pdf_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zh7Ak6PR7OQk",
        "outputId": "56ad8746-9360-42f3-b3fd-5f63c66ab3c7"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I3S46eVTwR4r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Any\n",
        "import chromadb\n",
        "import chromadb.config\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "class ChromaVectorStore:\n",
        "    def __init__(\n",
        "        self,\n",
        "        persist_dir: str = \"chroma_store\",\n",
        "        embedding_model_name: str = \"all-MiniLM-L6-v2\",\n",
        "        chunk_size: int = 1000,\n",
        "        chunk_overlap: int = 200,\n",
        "    ):\n",
        "        self.persist_dir = persist_dir\n",
        "        os.makedirs(self.persist_dir, exist_ok=True)\n",
        "\n",
        "        # Correctly initialize embedding model\n",
        "        self.embedding_function = SentenceTransformerEmbeddings(\n",
        "            model_name=embedding_model_name\n",
        "        )\n",
        "\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "\n",
        "        # Load existing DB if present\n",
        "        self.vectorstore = Chroma(\n",
        "            persist_directory=self.persist_dir,\n",
        "            embedding_function=self.embedding_function,\n",
        "        )\n",
        "\n",
        "        print(f\"[OK] Using embedding model: {embedding_model_name}\")\n",
        "\n",
        "    def build_from_documents(self, documents: List[Any]):\n",
        "        if not documents:\n",
        "            raise ValueError(\"No documents provided\")\n",
        "\n",
        "        print(f\"[INFO] Building vector store from {len(documents)} documents\")\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=self.chunk_size,\n",
        "            chunk_overlap=self.chunk_overlap,\n",
        "        )\n",
        "\n",
        "        chunks = splitter.split_documents(documents)\n",
        "\n",
        "        self.vectorstore = Chroma.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=self.embedding_function,\n",
        "            persist_directory=self.persist_dir,\n",
        "        )\n",
        "\n",
        "        self.vectorstore.persist()\n",
        "        print(f\"[OK] Vector store saved to {self.persist_dir}\")\n",
        "\n",
        "    def query(self, query_text: str, top_k: int = 5):\n",
        "        if not self.vectorstore:\n",
        "            raise RuntimeError(\"Vector store not initialized\")\n",
        "\n",
        "        print(f\"[INFO] Querying for: {query_text}\")\n",
        "\n",
        "        return self.vectorstore.similarity_search(query_text, k=top_k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QQLq5rqxXU-",
        "outputId": "33873c72-410d-44c6-d999-7f2416a10d36"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "# Initialize vector store\n",
        "chroma_store = ChromaVectorStore()\n",
        "\n",
        "# Build only if empty\n",
        "if chroma_store.vectorstore._collection.count() == 0:\n",
        "    chroma_store.build_from_documents(pdf_documents)\n",
        "else:\n",
        "    print(\"[INFO] Using existing Chroma DB\")\n",
        "\n",
        "# Query\n",
        "query = \"Explain attention mechanism in transformer neural networks\"\n",
        "query_results = chroma_store.query(query, top_k=2)\n",
        "\n",
        "# Display results\n",
        "if not query_results:\n",
        "    print(\"No relevant documents found.\")\n",
        "else:\n",
        "    for i, doc in enumerate(query_results, 1):\n",
        "        print(f\"\\nResult {i}:\")\n",
        "        print(doc.page_content)\n",
        "        print(\"Metadata:\", doc.metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
